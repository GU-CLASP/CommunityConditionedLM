%
% File acl2020.tex
%
%% Based on the style files for ACL 2020, which were
%% Based on the style files for ACL 2018, NAACL 2018/19, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2020}
\usepackage{times}
\usepackage{latexsym}
\renewcommand{\UrlFont}{\ttfamily\small}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B\textsc{ib}\TeX}

\title{Community-Conditioned Language Models}

\author{Anon.}

\date{}

\begin{document}
\maketitle
\begin{abstract}
\end{abstract}


\section{Introduction}

We propose to test the following hypotheses:

\begin{enumerate}
\item Different communities have different levels of linguistic
  complexity
\item different language models are able to recognize such differences
\item level at which the community embedding is taken into account in the language model influences this.
\item community vectors are correlated with extra-linguistic information.
\item stability is correlated with language complexity
\end{enumerate}

\section{Experimental setup}
\subsection{Data Sets}
\subsection{Models}
\subsection{Training scheme}

\section{Results and analysis}

% Computation of loss/community/model (show all)
\begin{table}
  \centering
  \begin{tabular}{ccc}
    todo &todo &todo 
  \end{tabular}
  \caption{Model losses per community}
  \label{tab:losses}
\end{table}
TODO commentary

TODO: say why we can't use the losses directly!
Turn a CCLM into a community classifier using Bayes theorem: The
probability that a given post $m$ belongs to a community $c_i$ can be
calculated as:
\[P(c=c_i | m) = P(m | c_i)\frac {P(m)} {P(c=c_i)}\]

$P(c=c_i)$ is the frequency of community $c_i$ in the dataset, and
$P(m | c_i)$ is given by the CCLM. $P(m)$ is our normalisation factor, which can be set so that
\[\sum_i P(c=c_i | m) = 1\].

Knowing that $m$ \emph{actually} comes from community $c_j$, we test
the recall and precision abilities of our classifier.  if we let
$C_{ij} = average_{m âˆˆ Posts(c_j)}(P(c=c_i | m))$ then $C$ is a
confusion matrix for it.

(TODO: on what set?)

TODO: show a few relevant matrices. (eg. show only best and worst model) and commentary.

TODO: why don't we use F scores or such bullshit?

TODO:Define \(D_j\) as the discrete probability distribution given by \(C_{ij}\) for fixed \(j\).

We then compute the perplexity of the classifier, per given community
$j$, as the exponential of the entropy of the distribution \(D_j\):

\[Ppl_j = e^{-\sum_i C_{ij} log(C_{ij})}\]


\(Ppl_j\) is a measure of the capability (or inability) of the model
to correctly identify a message as coming from a certain
community. (ie. it aggregates confusion on a column of the matrix).

We can then analyse the correlation between \(Ppl^M_j\) for various models $M$.


- Correlation between H(c,m) for various models. Identification of specific communities by hand
- Correlation between H(c,m) and Stability(c).

\section{Discussion and Conclusion}

- Comparison with topic modelling

\end{document}
