
@article{Bamman2014,
  title = {Gender Identity and Lexical Variation in Social Media},
  author = {Bamman, David and Eisenstein, Jacob and Schnoebelen, Tyler},
  year = {2014},
  journal = {Journal of Sociolinguistics},
  volume = {18},
  number = {2},
  pages = {135--160},
  issn = {1467-9841},
  doi = {10.1111/josl.12080},
  abstract = {We present a study of the relationship between gender, linguistic style, and social networks, using a novel corpus of 14,000 Twitter users. Prior quantitative work on gender often treats this social variable as a female/male binary; we argue for a more nuanced approach. By clustering Twitter users, we find a natural decomposition of the dataset into various styles and topical interests. Many clusters have strong gender orientations, but their use of linguistic resources sometimes directly conflicts with the population-level language statistics. We view these clusters as a more accurate reflection of the multifaceted nature of gendered language styles. Previous corpus-based work has also had little to say about individuals whose linguistic styles defy population-level gender patterns. To identify such individuals, we train a statistical classifier, and measure the classifier confidence for each individual in the dataset. Examining individuals whose language does not match the classifier's model for their gender, we find that they have social networks that include significantly fewer same-gender social connections and that, in general, social network homophily is correlated with the use of same-gender language markers. Pairing computational methods and social theory thus offers a new perspective on how gender emerges as individuals position themselves relative to audiences, topics, and mainstream gender norms.},
  copyright = {\textcopyright{} 2014 John Wiley \& Sons Ltd},
  langid = {english},
  keywords = {computational methods,computer-mediated communication,Gender,social media,social networks,style},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/josl.12080}
}

@inproceedings{Bamman2014a,
  title = {Distributed {{Representations}} of {{Geographically Situated Language}}},
  booktitle = {Proceedings of the 52nd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 2: Short {{Papers}})},
  author = {Bamman, David and Dyer, Chris and Smith, Noah A.},
  year = {2014},
  month = jun,
  pages = {828--834},
  publisher = {{Association for Computational Linguistics}},
  address = {{Baltimore, Maryland}},
  doi = {10.3115/v1/P14-2134},
  keywords = {cclm-rw}
}
% == BibTeX quality report for Bamman2014a:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused conferenceName: ACL 2014
% ? Unused libraryCatalog: ACLWeb
% ? Unused url: https://www.aclweb.org/anthology/P14-2134
% ? Unused version: 729

@article{Baumgartner2020,
  title = {The {{Pushshift Reddit Dataset}}},
  author = {Baumgartner, Jason and Zannettou, Savvas and Keegan, Brian and Squire, Megan and Blackburn, Jeremy},
  year = {2020},
  month = jan,
  journal = {arXiv:2001.08435 [cs]},
  eprint = {2001.08435},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Social media data has become crucial to the advancement of scientific understanding. However, even though it has become ubiquitous, just collecting large-scale social media data involves a high degree of engineering skill set and computational resources. In fact, research is often times gated by data engineering problems that must be overcome before analysis can proceed. This has resulted recognition of datasets as meaningful research contributions in and of themselves.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computers and Society,Computer Science - Social and Information Networks}
}
% == BibTeX quality report for Baumgartner2020:
% ? Possibly abbreviated journal title arXiv:2001.08435 [cs]
% ? Title looks like it was stored in title-case in Zotero
% ? Unused url: http://arxiv.org/abs/2001.08435
% ? Unused version: 164

@inproceedings{Burger2011,
  title = {Discriminating {{Gender}} on {{Twitter}}},
  booktitle = {Proceedings of the 2011 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Burger, John D. and Henderson, John and Kim, George and Zarrella, Guido},
  year = {2011},
  month = jul,
  pages = {1301--1309},
  publisher = {{Association for Computational Linguistics}},
  address = {{Edinburgh, Scotland, UK.}}
}
% == BibTeX quality report for Burger2011:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused conferenceName: EMNLP 2011
% ? Unused libraryCatalog: ACLWeb
% ? Unused url: https://www.aclweb.org/anthology/D11-1120
% ? Unused version: 172

@inproceedings{Ciot2013,
  title = {Gender {{Inference}} of {{Twitter Users}} in {{Non}}-{{English Contexts}}},
  booktitle = {Proceedings of the 2013 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Ciot, Morgane and Sonderegger, Morgan and Ruths, Derek},
  year = {2013},
  month = oct,
  pages = {1136--1145},
  publisher = {{Association for Computational Linguistics}},
  address = {{Seattle, Washington, USA}}
}
% == BibTeX quality report for Ciot2013:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused conferenceName: EMNLP 2013
% ? Unused libraryCatalog: ACLWeb
% ? Unused url: https://www.aclweb.org/anthology/D13-1114
% ? Unused version: 172

@book{Clark1996,
  title = {Using {{Language}}},
  author = {Clark, Herbert H.},
  year = {1996},
  month = may,
  publisher = {{Cambridge University Press}},
  abstract = {Herbert Clark argues that language use is more than the sum of a speaker speaking and a listener listening. It is the joint action that emerges when speakers and listeners, writers and readers perform their individual actions in coordination, as ensembles. In contrast to work within the cognitive sciences, which has seen language use as an individual process, and to work within the social sciences, which has seen it as a social process, the author argues strongly that language use embodies both individual and social processes.},
  isbn = {978-0-521-56745-9},
  langid = {english},
  keywords = {common ground,Language Arts \& Disciplines / Linguistics / General,Language Arts \& Disciplines / Vocabulary}
}
% == BibTeX quality report for Clark1996:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused libraryCatalog: Google Books
% ? Unused numPages: 452
% ? Unused version: 622

@inproceedings{Danescu-Niculescu-Mizil2011,
  title = {Mark My Words!: Linguistic Style Accommodation in Social Media},
  shorttitle = {Mark My Words!},
  booktitle = {Proceedings of the 20th International Conference on {{World}} Wide Web - {{WWW}} '11},
  author = {{Danescu-Niculescu-Mizil}, Cristian and Gamon, Michael and Dumais, Susan},
  year = {2011},
  pages = {745},
  publisher = {{ACM Press}},
  address = {{Hyderabad, India}},
  doi = {10.1145/1963405.1963509},
  abstract = {The psycholinguistic theory of communication accommodation accounts for the general observation that participants in conversations tend to converge to one another's communicative behavior: they coordinate in a variety of dimensions including choice of words, syntax, utterance length, pitch and gestures. In its almost forty years of existence, this theory has been empirically supported exclusively through smallscale or controlled laboratory studies. Here we address this phenomenon in the context of Twitter conversations. Undoubtedly, this setting is unlike any other in which accommodation was observed and, thus, challenging to the theory. Its novelty comes not only from its size, but also from the non real-time nature of conversations, from the 140 character length restriction, from the wide variety of social relation types, and from a design that was initially not geared towards conversation at all. Given such constraints, it is not clear a priori whether accommodation is robust enough to occur given the constraints of this new environment. To investigate this, we develop a probabilistic framework that can model accommodation and measure its effects. We apply it to a large Twitter conversational dataset specifically developed for this task. This is the first time the hypothesis of linguistic style accommodation has been examined (and verified) in a large scale, real world setting.},
  isbn = {978-1-4503-0632-4},
  langid = {english},
  keywords = {cclm-rw}
}
% == BibTeX quality report for Danescu-Niculescu-Mizil2011:
% ? Unsure about the formatting of the booktitle
% ? Unused conferenceName: the 20th international conference
% ? Unused libraryCatalog: Crossref
% ? Unused url: http://portal.acm.org/citation.cfm?doid=1963405.1963509
% ? Unused version: 735

@inproceedings{DelTredici2017,
  title = {Semantic {{Variation}} in {{Online Communities}} of {{Practice}}},
  booktitle = {{{IWCS}} 2017 - 12th {{International Conference}} on {{Computational Semantics}} - {{Long}} Papers},
  author = {Del Tredici, Marco and Fern{\'a}ndez, Raquel},
  year = {2017},
  keywords = {cclm-rw}
}
% == BibTeX quality report for DelTredici2017:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? Unused libraryCatalog: ACLWeb
% ? Unused url: https://www.aclweb.org/anthology/W17-6804
% ? Unused version: 729

@book{deSaussure2011,
  title = {Course in {{General Linguistics}}: Translated by {{Wade Baskin}}. {{Edited}} by {{Perry Meisel}} and {{Haun Saussy}}},
  shorttitle = {Course in {{General Linguistics}}},
  author = {{de Saussure}, Ferdinand},
  editor = {Meisel, Perry and Saussy, Haun},
  translator = {Baskin, Wade},
  year = {2011},
  publisher = {{Columbia University Press}},
  abstract = {The founder of modern linguistics, Ferdinand de Saussure inaugurated semiology, structuralism, and deconstruction and made possible the work of Jacques Derrida, Roland Barthes, Michel Foucault, and Jacques Lacan, thus enabling the development of French feminism, gender studies, New Historicism, and postcolonialism. Based on Saussure's lectures, {$<$}em{$>$}Course in General Linguistics{$<$}/em{$>$} (1916) traces the rise and fall of the historical linguistics in which Saussure was trained, the synchronic or structural linguistics with which he replaced it, and the new look of diachronic linguistics that followed this change. Most important, Saussure presents the principles of a new linguistic science that includes the invention of semiology, or the theory of the "signifier," the "signified," and the "sign" that they combine to produce.  This is the first critical edition of  \emph{Course in General Linguistics}  to appear in English and restores Wade Baskin's original translation of 1959, in which the terms "signifier" and "signified" are introduced into English in this precise way. Baskin renders Saussure clearly and accessibly, allowing readers to experience his shift of the theory of reference from mimesis to performance and his expansion of poetics to include all media, including the life sciences and environmentalism. An introduction situates Saussure within the history of ideas and describes the history of scholarship that made {$<$}em{$>$}Course in General Linguistics{$<$}/em{$>$} legendary. New endnotes enlarge Saussure's contexts to include literary criticism, cultural studies, and philosophy.}
}
% == BibTeX quality report for deSaussure2011:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused libraryCatalog: JSTOR
% ? Unused url: http://www.jstor.org/stable/10.7312/saus15726
% ? Unused version: 532

@article{Eckert1992,
  title = {Communities of Practice: Where Language, Gender, and Power All Live},
  author = {Eckert, Penelope and {McConnell-Ginet}, Sally},
  year = {1992},
  journal = {Locating Power, Proceedings of the 1992 Berkeley Women and Language Conference},
  pages = {89--99},
  langid = {english}
}

@inproceedings{Eisenstein2010,
  title = {A {{Latent Variable Model}} for {{Geographic Lexical Variation}}},
  booktitle = {Proceedings of the 2010 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Eisenstein, Jacob and O'Connor, Brendan and Smith, Noah A. and Xing, Eric P.},
  year = {2010},
  month = oct,
  pages = {1277--1287},
  publisher = {{Association for Computational Linguistics}},
  address = {{Cambridge, MA}},
  keywords = {cclm-rw}
}
% == BibTeX quality report for Eisenstein2010:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused conferenceName: EMNLP 2010
% ? Unused libraryCatalog: ACLWeb
% ? Unused url: https://www.aclweb.org/anthology/D10-1124
% ? Unused version: 729

@inproceedings{Feng2010,
  title = {Visual {{Information}} in {{Semantic Representation}}},
  author = {Feng, Yansong and Lapata, Mirella},
  year = {2010},
  month = jul,
  pages = {91--99},
  abstract = {The question of how meaning might be acquired by young children and represented by adult speakers of a language is one of the most debated topics in cognitive science. Existing semantic representation models are primarily amodal based on information provided by the linguistic input despite ample evidence indicating that the cognitive system is also sensitive to perceptual information. In this work we exploit the vast resource of images and associated documents available on the web and develop a model of multimodal meaning representation which is based on the linguistic and visual context. Experimental results show that a closer correspondence to human data can be obtained by taking the visual modality into account.}
}
% == BibTeX quality report for Feng2010:
% Missing required field 'booktitle'
% ? Title looks like it was stored in title-case in Zotero
% ? Unused libraryCatalog: ResearchGate
% ? Unused version: 172

@article{Gliniecka2021,
  title = {{{AoIR}} Ethics Panel 2: Platform Challenges},
  shorttitle = {{{AOIR ETHICS PANEL}} 2},
  author = {Gliniecka, Martyna and Reagle, Joseph and Proferes, Nicholas and Fiesler, Casey and Gilbert, Sarah and Jones, Naiyan and Zimmer, Michael and Xia, Huichuan and Sehat, Connie Moon and Prabhakar, Tarunima and Kaminski, Aleksei},
  year = {2021},
  month = sep,
  journal = {AoIR Selected Papers of Internet Research},
  issn = {2162-3317},
  doi = {10.5210/spir.v2021i0.12096},
  abstract = {This panel is one of two sessions organized by the AoIR Ethics Working Committee. It collects five papers exploring a broad (but in many ways common) set of ethical dilemmas faced by researchers engaged with specific platforms such as Reddit, Amazon's Mechanical Turk, and private messaging platforms. These include: a study of people's online conversations about health matters on Reddit in support of a proposed situated ethics framework for researchers working with publicly available data; an exploration into sourcing practices among Reddit researchers to determine if their sources could be unmasked and located in Reddit archives; a broader systematic review of over 700 research studies that used Reddit data to assess the kinds of analysis and methods researchers are engaging in as well as any ethical considerations that emerge when researching Reddit; a critical examination of the use of Amazon's Mechanical Turk for academic research; and an investigation into current practices and ethical dilemmas faced when researching closed messaging applications and their users. Taken together, these papers illuminate emerging ethical dilemmas facing researchers when investigating novel platforms and user communities; challenges often not fully addressed\textendash if even contemplated\textendash in existing ethical guidelines. These papers are among those under consideration for publication in a special issue of the Journal of Information, Communication and Ethics in Society associated with the AoIR Ethics Working Committee and AoIR2021.},
  copyright = {Copyright (c) 2021 AoIR Selected Papers of Internet Research},
  langid = {english},
  keywords = {messaging}
}

@book{Gower2004,
  title = {Procrustes Problems},
  author = {Gower, J. C. and Dijksterhuis, Garmt B.},
  year = {2004},
  series = {Oxford Statistical Science Series},
  number = {30},
  publisher = {{Oxford University Press}},
  address = {{Oxford ; New York}},
  isbn = {978-0-19-851058-1},
  lccn = {QA278 .G686 2004},
  keywords = {Multivariate analysis},
  annotation = {OCLC: ocm53156636}
}

@article{Grieve2019,
  title = {Mapping {{Lexical Dialect Variation}} in {{British English Using Twitter}}},
  author = {Grieve, Jack and Montgomery, Chris and Nini, Andrea and Murakami, Akira and Guo, Diansheng},
  year = {2019},
  journal = {Frontiers in Artificial Intelligence},
  volume = {2},
  pages = {11},
  issn = {2624-8212},
  doi = {10.3389/frai.2019.00011},
  abstract = {There is a growing trend in regional dialectology to analyse large corpora of social media data, but it is unclear if the results of these studies can be generalized to language as a whole. To assess the generalizability of Twitter dialect maps, this paper presents the first systematic comparison of regional lexical variation in Twitter corpora and traditional survey data. We compare the regional patterns found in 139 lexical dialect maps based on a 1.8 billion word corpus of geolocated UK Twitter data and the BBC Voices dialect survey. A spatial analysis of these 139 map pairs finds a broad alignment between these two data sources, offering evidence that both approaches to data collection allow for the same basic underlying regional patterns to be identified. We argue that these results license the use of Twitter corpora for general inquiries into regional lexical variation and change.},
  keywords = {cclm-rw}
}
% == BibTeX quality report for Grieve2019:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused libraryCatalog: Frontiers
% ? Unused url: https://www.frontiersin.org/article/10.3389/frai.2019.00011
% ? Unused version: 735

@incollection{Gumperz1972,
  title = {The {{Speech Community}}},
  booktitle = {Language and Social Context: Selected Readings},
  author = {Gumperz, J},
  editor = {Giglioli, Pier Paolo},
  year = {1972},
  publisher = {{Harmondsworth : Penguin}},
  abstract = {399 pages ; 18 cm; Includes bibliographical references; Hymes, D. Toward ethnographies of communication.--Fishman, J.A. The sociology of language.--Goffman, E. The neglected situation.--Basso, K.H. To give up on words: silence in Western Apache culture.--Frake, C.O. How to ask for a drink in Subanun.--Schegloff, E.A. Notes on a conversational practice: formulating place.--Searle, J. What is a speech act?--Bernstein, B. Social class, language and socialization.--Labov, W. The logic of nonstandard English.--Gumperz, J. The speech community.--Ferguson, C.A. Diglossia.--Brown, R. and Gilman, A. The pronouns of power and solidarity.--Labov, W. The study of language in its social context.--Goody, J. and Watt, I. The consequences of literacy.--Inglehart, R. and Woodward, M. Language conflicts and the political community},
  isbn = {978-0-14-080244-3 978-0-14-022649-2},
  langid = {english},
  keywords = {Sociolinguistics}
}
% == BibTeX quality report for Gumperz1972:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused libraryCatalog: Internet Archive
% ? Unused url: http://archive.org/details/languagesocialco0000unse
% ? Unused version: 171

@inproceedings{Hamilton2016a,
  title = {Diachronic {{Word Embeddings Reveal Statistical Laws}} of {{Semantic Change}}},
  booktitle = {Proceedings of the 54th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: Long {{Papers}})},
  author = {Hamilton, William L. and Leskovec, Jure and Jurafsky, Dan},
  year = {2016},
  pages = {1489--1501},
  publisher = {{Association for Computational Linguistics}},
  address = {{Berlin, Germany}},
  doi = {10.18653/v1/P16-1141},
  abstract = {Understanding how words change their meanings over time is key to models of language and cultural evolution, but historical data on meaning is scarce, making theories hard to develop and test. Word embeddings show promise as a diachronic tool, but have not been carefully evaluated. We develop a robust methodology for quantifying semantic change by evaluating word embeddings (PPMI, SVD, word2vec) against known historical changes. We then use this methodology to reveal statistical laws of semantic evolution. Using six historical corpora spanning four languages and two centuries, we propose two quantitative laws of semantic change: (i) the law of conformity\textemdash the rate of semantic change scales with an inverse power-law of word frequency; (ii) the law of innovation\textemdash independent of frequency, words that are more polysemous have higher rates of semantic change.},
  langid = {english}
}
% == BibTeX quality report for Hamilton2016a:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused libraryCatalog: DOI.org (Crossref)
% ? Unused url: http://aclweb.org/anthology/P16-1141
% ? Unused version: 745

@incollection{Hawkins2014,
  title = {Major Contributions from Formal Linguistics to the Complexity Debate},
  booktitle = {Measuring {{Grammatical Complexity}}},
  author = {Hawkins, John A.},
  editor = {Newmeyer, Frederick J. and Preston, Laurel B.},
  year = {2014},
  month = oct,
  pages = {14--36},
  publisher = {{Oxford University Press}},
  doi = {10.1093/acprof:oso/9780199685301.003.0002},
  isbn = {978-0-19-968530-1}
}

@article{Hochreiter1997,
  title = {Long {{Short}}-{{Term Memory}}},
  author = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  year = {1997},
  month = nov,
  journal = {Neural Computation},
  volume = {9},
  number = {8},
  pages = {1735--1780},
  publisher = {{MIT Press}},
  issn = {0899-7667},
  doi = {10.1162/neco.1997.9.8.1735},
  abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.}
}
% == BibTeX quality report for Hochreiter1997:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused libraryCatalog: MIT Press Journals
% ? Unused url: https://doi.org/10.1162/neco.1997.9.8.1735
% ? Unused version: 171

@misc{Honnibal2017,
  title = {{{spaCy}} 2: Natural Language Understanding with {{Bloom}} Embeddings, Convolutional Neural Networks and Incremental Parsing},
  author = {Honnibal, Matthew and Montani, Ines},
  year = {2017},
  howpublished = {Explosion}
}

@inproceedings{Hovy2015,
  title = {Demographic {{Factors Improve Classification Performance}}},
  booktitle = {Proceedings of the 53rd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} and the 7th {{International Joint Conference}} on {{Natural Language Processing}} ({{Volume}} 1: Long {{Papers}})},
  author = {Hovy, Dirk},
  year = {2015},
  month = jul,
  pages = {752--762},
  publisher = {{Association for Computational Linguistics}},
  address = {{Beijing, China}},
  doi = {10.3115/v1/P15-1073}
}
% == BibTeX quality report for Hovy2015:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused conferenceName: ACL-IJCNLP 2015
% ? Unused libraryCatalog: ACLWeb
% ? Unused url: https://www.aclweb.org/anthology/P15-1073
% ? Unused version: 172

@inproceedings{Huang2014,
  title = {Enriching {{Cold Start Personalized Language Model Using Social Network Information}}},
  booktitle = {Proceedings of the 52nd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 2: Short {{Papers}})},
  author = {Huang, Yu-Yang and Yan, Rui and Kuo, Tsung-Ting and Lin, Shou-De},
  year = {2014},
  pages = {611--617},
  publisher = {{Association for Computational Linguistics}},
  address = {{Baltimore, Maryland}},
  doi = {10.3115/v1/P14-2100},
  abstract = {Personalized language models are useful in many applications, such as personalized search and personalized recommendation. Nevertheless, it is challenging to build a personalized language model for cold start users, in which the size of the training corpus of those users is too small to create a reasonably accurate and representative model. We introduce a generalized framework to enrich the personalized language models for cold start users. The cold start problem is solved with content written by friends on social network services. Our framework consists of a mixture language model, whose mixture weights are estimated with a factor graph. The factor graph is used to incorporate prior knowledge and heuristics to identify the most appropriate weights. The intrinsic and extrinsic experiments show significant improvement on cold start users.},
  langid = {english},
  keywords = {cclm-rw}
}
% == BibTeX quality report for Huang2014:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused libraryCatalog: DOI.org (Crossref)
% ? Unused url: http://aclweb.org/anthology/P14-2100
% ? Unused version: 731

@inproceedings{Kalchbrenner2013,
  title = {Recurrent {{Continuous Translation Models}}},
  booktitle = {Proceedings of the 2013 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Kalchbrenner, Nal and Blunsom, Phil},
  year = {2013},
  pages = {10},
  address = {{Seattle, Washington}},
  abstract = {We introduce a class of probabilistic continuous translation models called Recurrent Continuous Translation Models that are purely based on continuous representations for words, phrases and sentences and do not rely on alignments or phrasal translation units. The models have a generation and a conditioning aspect. The generation of the translation is modelled with a target Recurrent Language Model, whereas the conditioning on the source sentence is modelled with a Convolutional Sentence Model. Through various experiments, we show first that our models obtain a perplexity with respect to gold translations that is {$>$} 43\% lower than that of stateof-the-art alignment-based translation models. Secondly, we show that they are remarkably sensitive to the word order, syntax, and meaning of the source sentence despite lacking alignments. Finally we show that they match a state-of-the-art system when rescoring n-best lists of translations.},
  langid = {english}
}
% == BibTeX quality report for Kalchbrenner2013:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused conferenceName: EMNLP
% ? Unused libraryCatalog: Zotero
% ? Unused version: 164

@article{Kovacs2020,
  title = {Language-{{Style Similarity}} and {{Social Networks}}},
  author = {Kovacs, Balazs and Kleinbaum, Adam M.},
  year = {2020},
  month = feb,
  journal = {Psychological Science},
  volume = {31},
  number = {2},
  pages = {202--213},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797619894557},
  abstract = {This research demonstrates that linguistic similarity predicts network-tie formation and that friends exhibit linguistic convergence over time. In Study 1, we analyzed the linguistic styles and the emerging social network of a complete cohort of 285 students. In Study 2, we analyzed a large-scale data set of online reviews. In both studies, we collected data in two waves to examine changes in both social networks and linguistic styles. Using the Linguistic Inquiry and Word Count (LIWC) framework, we analyzed the text of students' essays and of 1.7 million reviews by 159,651 Yelp reviewers. Consistent with our theory, results showed that similarity in linguistic style corresponded to a higher likelihood of friendship formation and persistence and that friendship ties, in turn, corresponded to a convergence in linguistic style. We discuss the implications of the coevolution of linguistic styles and social networks, which contribute to the formation of relational echo chambers.},
  langid = {english}
}
% == BibTeX quality report for Kovacs2020:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused journalAbbreviation: Psychol Sci
% ? Unused libraryCatalog: DOI.org (Crossref)
% ? Unused url: http://journals.sagepub.com/doi/10.1177/0956797619894557
% ? Unused version: 743

@article{Kulkarni2016,
  title = {Domain {{Adaptation}} for {{Named Entity Recognition}} in {{Online Media}} with {{Word Embeddings}}},
  author = {Kulkarni, Vivek and Mehdad, Yashar and Chevalier, Troy},
  year = {2016},
  month = dec,
  journal = {arXiv:1612.00148 [cs]},
  eprint = {1612.00148},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Content on the Internet is heterogeneous and arises from various domains like News, Entertainment, Finance and Technology. Understanding such content requires identifying named entities (persons, places and organizations) as one of the key steps. Traditionally Named Entity Recognition (NER) systems have been built using available annotated datasets (like CoNLL, MUC) and demonstrate excellent performance. However, these models fail to generalize onto other domains like Sports and Finance where conventions and language use can differ significantly. Furthermore, several domains do not have large amounts of annotated labeled data for training robust Named Entity Recognition models. A key step towards this challenge is to adapt models learned on domains where large amounts of annotated training data are available to domains with scarce annotated data. In this paper, we propose methods to effectively adapt models learned on one domain onto other domains using distributed word representations. First we analyze the linguistic variation present across domains to identify key linguistic insights that can boost performance across domains. We propose methods to capture domain specific semantics of word usage in addition to global semantics. We then demonstrate how to effectively use such domain specific knowledge to learn NER models that outperform previous baselines in the domain adaptation setting.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval}
}
% == BibTeX quality report for Kulkarni2016:
% ? Possibly abbreviated journal title arXiv:1612.00148 [cs]
% ? Title looks like it was stored in title-case in Zotero
% ? Unused url: http://arxiv.org/abs/1612.00148
% ? Unused version: 704

@inproceedings{Kumar2018,
  title = {Community {{Interaction}} and {{Conflict}} on the {{Web}}},
  booktitle = {Proceedings of the 2018 {{World Wide Web Conference}} on {{World Wide Web}} - {{WWW}} '18},
  author = {Kumar, Srijan and Hamilton, William L. and Leskovec, Jure and Jurafsky, Dan},
  year = {2018},
  pages = {933--943},
  publisher = {{ACM Press}},
  address = {{Lyon, France}},
  doi = {10.1145/3178876.3186141},
  abstract = {Users organize themselves into communities on web platform60 s. These communities can interact with one another, often leading to conflicts and toxic interactions. However, little is known about the mechanisms of interactions between communities and how th40ey impact users.},
  isbn = {978-1-4503-5639-8},
  langid = {english},
  keywords = {cclm-rw}
}
% == BibTeX quality report for Kumar2018:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused conferenceName: the 2018 World Wide Web Conference
% ? Unused libraryCatalog: DOI.org (Crossref)
% ? Unused url: http://dl.acm.org/citation.cfm?doid=3178876.3186141
% ? Unused version: 730

@article{Lau2017,
  title = {Grammaticality, {{Acceptability}}, and {{Probability}}: A {{Probabilistic View}} of {{Linguistic Knowledge}}},
  shorttitle = {Grammaticality, {{Acceptability}}, and {{Probability}}},
  author = {Lau, Jey Han and Clark, Alexander and Lappin, Shalom},
  year = {2017},
  journal = {Cognitive Science},
  volume = {41},
  number = {5},
  pages = {1202--1241},
  issn = {1551-6709},
  doi = {10.1111/cogs.12414},
  abstract = {The question of whether humans represent grammatical knowledge as a binary condition on membership in a set of well-formed sentences, or as a probabilistic property has been the subject of debate among linguists, psychologists, and cognitive scientists for many decades. Acceptability judgments present a serious problem for both classical binary and probabilistic theories of grammaticality. These judgements are gradient in nature, and so cannot be directly accommodated in a binary formal grammar. However, it is also not possible to simply reduce acceptability to probability. The acceptability of a sentence is not the same as the likelihood of its occurrence, which is, in part, determined by factors like sentence length and lexical frequency. In this paper, we present the results of a set of large-scale experiments using crowd-sourced acceptability judgments that demonstrate gradience to be a pervasive feature in acceptability judgments. We then show how one can predict acceptability judgments on the basis of probability by augmenting probabilistic language models with an acceptability measure. This is a function that normalizes probability values to eliminate the confounding factors of length and lexical frequency. We describe a sequence of modeling experiments with unsupervised language models drawn from state-of-the-art machine learning methods in natural language processing. Several of these models achieve very encouraging levels of accuracy in the acceptability prediction task, as measured by the correlation between the acceptability measure scores and mean human acceptability values. We consider the relevance of these results to the debate on the nature of grammatical competence, and we argue that they support the view that linguistic knowledge can be intrinsically probabilistic.},
  copyright = {Copyright \textcopyright{} 2016 Cognitive Science Society, Inc.},
  langid = {english},
  keywords = {Grammaticality,Probabilistic modeling,Syntactic knowledge},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12414}
}
% == BibTeX quality report for Lau2017:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused libraryCatalog: Wiley Online Library
% ? Unused url: http://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12414
% ? Unused version: 165

@inproceedings{Lau2017a,
  title = {Topically {{Driven Neural Language Model}}},
  booktitle = {Proceedings of the 55th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: Long {{Papers}})},
  author = {Lau, Jey Han and Baldwin, Timothy and Cohn, Trevor},
  year = {2017},
  month = jul,
  pages = {355--365},
  publisher = {{Association for Computational Linguistics}},
  address = {{Vancouver, Canada}},
  doi = {10.18653/v1/P17-1033},
  abstract = {Language models are typically applied at the sentence level, without access to the broader document context. We present a neural language model that incorporates document context in the form of a topic model-like architecture, thus providing a succinct representation of the broader document context outside of the current sentence. Experiments over a range of datasets demonstrate that our model outperforms a pure sentence-based model in terms of language model perplexity, and leads to topics that are potentially more coherent than those produced by a standard LDA topic model. Our model also has the ability to generate related sentences for a topic, providing another way to interpret topics.}
}
% == BibTeX quality report for Lau2017a:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused conferenceName: ACL 2017
% ? Unused libraryCatalog: ACLWeb
% ? Unused url: https://www.aclweb.org/anthology/P17-1033
% ? Unused version: 167

@article{Loshchilov2019,
  title = {Decoupled {{Weight Decay Regularization}}},
  author = {Loshchilov, Ilya and Hutter, Frank},
  year = {2019},
  month = jan,
  journal = {arXiv:1711.05101 [cs, math]},
  eprint = {1711.05101},
  eprinttype = {arxiv},
  primaryclass = {cs, math},
  abstract = {L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is \textbackslash emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it "weight decay" in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by \textbackslash emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at https://github.com/loshchil/AdamW-and-SGDW},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Mathematics - Optimization and Control}
}
% == BibTeX quality report for Loshchilov2019:
% ? Possibly abbreviated journal title arXiv:1711.05101 [cs, math]
% ? Title looks like it was stored in title-case in Zotero
% ? Unused url: http://arxiv.org/abs/1711.05101
% ? Unused version: 170

@article{Lucy2021,
  title = {Characterizing {{English Variation}} across {{Social Media Communities}} with {{BERT}}},
  author = {Lucy, Li and Bamman, David},
  year = {2021},
  month = may,
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {9},
  pages = {538--556},
  issn = {2307-387X},
  doi = {10.1162/tacl_a_00383},
  abstract = {Much previous work characterizing language variation across Internet social groups has focused on the types of words used by these groups. We extend this type of study by employing BERT to characterize variation in the senses of words as well, analyzing two months of English comments in 474 Reddit communities. The specificity of different sense clusters to a community, combined with the specificity of a community's unique word types, is used to identify cases where a social group's language deviates from the norm. We validate our metrics using user-created glossaries and draw on sociolinguistic theories to connect language variation with trends in community behavior. We find that communities with highly distinctive language are medium-sized, and their loyal and highly engaged users interact in dense networks.},
  keywords = {cclm-rw}
}
% == BibTeX quality report for Lucy2021:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused libraryCatalog: Silverchair
% ? Unused url: https://doi.org/10.1162/tacl_a_00383
% ? Unused version: 731

@inproceedings{Martin2017,
  title = {Community2vec: Vector Representations of Online Communities Encode Semantic Relationships},
  shorttitle = {Community2vec},
  booktitle = {Proceedings of the {{Second Workshop}} on {{NLP}} and {{Computational Social Science}}},
  author = {Martin, Trevor},
  year = {2017},
  month = aug,
  pages = {27--31},
  publisher = {{Association for Computational Linguistics}},
  address = {{Vancouver, Canada}},
  doi = {10.18653/v1/W17-2904},
  abstract = {Vector embeddings of words have been shown to encode meaningful semantic relationships that enable solving of complex analogies. This vector embedding concept has been extended successfully to many different domains and in this paper we both create and visualize vector representations of an unstructured collection of online communities based on user participation. Further, we quantitatively and qualitatively show that these representations allow solving of semantically meaningful community analogies and also other more general types of relationships. These results could help improve community recommendation engines and also serve as a tool for sociological studies of community relatedness.},
  keywords = {cclm-rw}
}

@inproceedings{Nguyen2013,
  title = {How {{Old Do You Think I Am}}?: A {{Study}} of {{Language}} and {{Age}} in {{Twitter}}},
  booktitle = {Proceedings of the {{Seventh International AAAI Conference}} on {{Weblogs}} and {{Social Media}}},
  author = {Nguyen, Dong and Gravel, Rilana and Trieschnigg, Dolf and Meder, Theo},
  year = {2013},
  pages = {10},
  abstract = {In this paper we focus on the connection between age and language use, exploring age prediction of Twitter users based on their tweets. We discuss the construction of a fine-grained annotation effort to assign ages and life stages to Twitter users. Using this dataset, we explore age prediction in three different ways: classifying users into age categories, by life stages, and predicting their exact age. We find that an automatic system achieves better performance than humans on these tasks and that both humans and the automatic systems have difficulties predicting the age of older people. Moreover, we present a detailed analysis of variables that change with age. We find strong patterns of change, and that most changes occur at young ages.},
  langid = {english}
}
% == BibTeX quality report for Nguyen2013:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused libraryCatalog: Zotero
% ? Unused version: 173

@article{Nguyen2016,
  title = {Computational {{Sociolinguistics}}: A {{Survey}}},
  shorttitle = {Computational {{Sociolinguistics}}},
  author = {Nguyen, Dong and Do{\u g}ru{\"o}z, A. Seza and Ros{\'e}, Carolyn P. and {de Jong}, Franciska},
  year = {2016},
  month = sep,
  journal = {Computational Linguistics},
  volume = {42},
  number = {3},
  pages = {537--593},
  issn = {0891-2017},
  doi = {10.1162/COLI_a_00258},
  abstract = {Language is a social phenomenon and variation is inherent to its social nature. Recently, there has been a surge of interest within the computational linguistics (CL) community in the social dimension of language. In this article we present a survey of the emerging field of ``computational sociolinguistics'' that reflects this increased interest. We aim to provide a comprehensive overview of CL research on sociolinguistic themes, featuring topics such as the relation between language and social identity, language use in social interaction, and multilingual communication. Moreover, we demonstrate the potential for synergy between the research communities involved, by showing how the large-scale data-driven methods that are widely used in CL can complement existing sociolinguistic studies, and how sociolinguistics can inform and challenge the methods and assumptions used in CL studies. We hope to convey the possible benefits of a closer collaboration between the two communities and conclude with a discussion of open challenges.},
  keywords = {cclm-rw}
}
% == BibTeX quality report for Nguyen2016:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused libraryCatalog: Silverchair
% ? Unused url: https://doi.org/10.1162/COLI_a_00258
% ? Unused version: 737

@inproceedings{Noble2021,
  title = {Semantic Shift in Social Networks},
  booktitle = {Proceedings of *{{SEM}} 2021: The {{Tenth Joint Conference}} on {{Lexical}} and {{Computational Semantics}}},
  author = {Noble, Bill and Sayeed, Asad and Fern{\'a}ndez, Raquel and Larsson, Staffan},
  year = {2021},
  month = aug,
  pages = {26--37},
  publisher = {{Association for Computational Linguistics}},
  address = {{Online}},
  doi = {10.18653/v1/2021.starsem-1.3},
  abstract = {Just as the meaning of words is tied to the communities in which they are used, so too is semantic change. But how does lexical semantic change manifest differently across different communities? In this work, we investigate the relationship between community structure and semantic change in 45 communities from the social media website Reddit. We use distributional methods to quantify lexical semantic change and induce a social network on communities, based on interactions between members. We explore the relationship between semantic change and the clustering coefficient of a community's social network graph, as well as community size and stability. While none of these factors are found to be significant on their own, we report a significant effect of their three-way interaction. We also report on significant word-level effects of frequency and change in frequency, which replicate previous findings.},
  keywords = {cclm-rw}
}

@inproceedings{OConnor2010,
  title = {A Mixture Model of Demographic Lexical Variation},
  booktitle = {In {{Proceedings}} of {{NIPS Workshop}} on {{Machine Learning}} for {{Social Computing}}},
  author = {O'Connor, Brendan and Eisenstein, Jacob and Xing, Eric P and Smith, Noah A},
  year = {2010},
  pages = {6},
  publisher = {{2010}},
  address = {{Vancouver, BC, Canada}},
  abstract = {We propose a Bayesian generative model of how demographic social factors influence lexical choice. We apply the method to a corpus of geo-tagged Twitter messages originating from mobile phones, cross-referenced against U.S. Census demographic data. Our method discovers communities jointly defined by linguistic and demographic properties.},
  langid = {english}
}

@inproceedings{Peters2018a,
  title = {Dissecting {{Contextual Word Embeddings}}: Architecture and {{Representation}}},
  booktitle = {Proceedings of the 2018 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Peters, Matthew and Neumann, Mark and Zettlemoyer, Luke and Yih, Wen-tau},
  year = {2018},
  pages = {1499--1509},
  address = {{Brussels, Belgium}},
  abstract = {Contextual word representations derived from pre-trained bidirectional language models (biLMs) have recently been shown to provide significant improvements to the state of the art for a wide range of NLP tasks. However, many questions remain as to how and why these models are so effective. In this paper, we present a detailed empirical study of how the choice of neural architecture (e.g. LSTM, CNN, or self attention) influences both end task accuracy and qualitative properties of the representations that are learned. We show there is a tradeoff between speed and accuracy, but all architectures learn high quality contextual representations that outperform word embeddings for four challenging NLP tasks. Additionally, all architectures learn representations that vary with network depth, from exclusively morphological based at the word embedding layer through local syntax based in the lower contextual layers to longer range semantics such coreference at the upper layers. Together, these results suggest that unsupervised biLMs, independent of architecture, are learning much more about the structure of language than previously appreciated.},
  langid = {english}
}
% == BibTeX quality report for Peters2018a:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused conferenceName: Conference on Empirical Methods in Natural Language Processing
% ? Unused libraryCatalog: Zotero
% ? Unused version: 285

@inproceedings{Shoemark2017,
  title = {Aye or Naw, Whit Dae Ye Hink? Scottish Independence and Linguistic Identity on Social Media},
  shorttitle = {Aye or Naw, Whit Dae Ye Hink?},
  booktitle = {Proceedings of the 15th {{Conference}} of the {{European Chapter}} of the {{Association}} for {{Computational Linguistics}}: Volume 1, {{Long Papers}}},
  author = {Shoemark, Philippa and Sur, Debnil and Shrimpton, Luke and Murray, Iain and Goldwater, Sharon},
  year = {2017},
  month = apr,
  pages = {1239--1248},
  publisher = {{Association for Computational Linguistics}},
  address = {{Valencia, Spain}},
  abstract = {Political surveys have indicated a relationship between a sense of Scottish identity and voting decisions in the 2014 Scottish Independence Referendum. Identity is often reflected in language use, suggesting the intuitive hypothesis that individuals who support Scottish independence are more likely to use distinctively Scottish words than those who oppose it. In the first large-scale study of sociolinguistic variation on social media in the UK, we identify distinctively Scottish terms in a data-driven way, and find that these terms are indeed used at a higher rate by users of pro-independence hashtags than by users of anti-independence hashtags. However, we also find that in general people are less likely to use distinctively Scottish words in tweets with referendum-related hashtags than in their general Twitter activity. We attribute this difference to style shifting relative to audience, aligning with previous work showing that Twitter users tend to use fewer local variants when addressing a broader audience.},
  keywords = {cclm-rw}
}

@article{Stalnaker2002,
  title = {Common {{Ground}}},
  author = {Stalnaker, Robert},
  year = {2002},
  journal = {Linguistics and Philosophy},
  volume = {25},
  number = {5-6},
  pages = {701--721}
}
% == BibTeX quality report for Stalnaker2002:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused libraryCatalog: PhilPapers
% ? Unused version: 548

@article{Vaswani2017,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  year = {2017},
  month = jun,
  journal = {arXiv:1706.03762 [cs]},
  eprint = {1706.03762},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning}
}
% == BibTeX quality report for Vaswani2017:
% ? Possibly abbreviated journal title arXiv:1706.03762 [cs]
% ? Title looks like it was stored in title-case in Zotero
% ? Unused url: http://arxiv.org/abs/1706.03762
% ? Unused version: 163

@article{Vinyals2015,
  title = {Show and {{Tell}}: A {{Neural Image Caption Generator}}},
  shorttitle = {Show and {{Tell}}},
  author = {Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
  year = {2015},
  month = apr,
  journal = {arXiv:1411.4555 [cs]},
  eprint = {1411.4555},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. For instance, while the current state-of-the-art BLEU-1 score (the higher the better) on the Pascal dataset is 25, our approach yields 59, to be compared to human performance around 69. We also show BLEU-1 score improvements on Flickr30k, from 56 to 66, and on SBU, from 19 to 28. Lastly, on the newly released COCO dataset, we achieve a BLEU-4 of 27.7, which is the current state-of-the-art.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}
% == BibTeX quality report for Vinyals2015:
% ? Possibly abbreviated journal title arXiv:1411.4555 [cs]
% ? Title looks like it was stored in title-case in Zotero
% ? Unused url: http://arxiv.org/abs/1411.4555
% ? Unused version: 164

@article{Yang2017,
  title = {Overcoming {{Language Variation}} in {{Sentiment Analysis}} with {{Social Attention}}},
  author = {Yang, Yi and Eisenstein, Jacob},
  year = {2017},
  month = dec,
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {5},
  pages = {295--307},
  issn = {2307-387X},
  doi = {10.1162/tacl_a_00062},
  abstract = {Variation in language is ubiquitous, particularly in newer forms of writing such as social media. Fortunately, variation is not random; it is often linked to social properties of the author. In this paper, we show how to exploit social networks to make sentiment analysis more robust to social language variation. The key idea is linguistic homophily: the tendency of socially linked individuals to use language in similar ways. We formalize this idea in a novel attention-based neural network architecture, in which attention is divided among several basis models, depending on the author's position in the social network. This has the effect of smoothing the classification function across the social network, and makes it possible to induce personalized classifiers even for authors for whom there is no labeled data or demographic metadata. This model significantly improves the accuracies of sentiment analysis on Twitter and on review data.},
  langid = {english}
}
% == BibTeX quality report for Yang2017:
% ? Title looks like it was stored in title-case in Zotero
% ? Unused journalAbbreviation: TACL
% ? Unused libraryCatalog: DOI.org (Crossref)
% ? Unused url: https://www.mitpressjournals.org/doi/abs/10.1162/tacl_a_00062
% ? Unused version: 172

@article{Zhang2018,
  title = {Community {{Identity}} and {{User Engagement}} in a {{Multi}}-{{Community Landscape}}},
  author = {Zhang, Justine and Hamilton, William L and {Danescu-Niculescu-Mizil}, Cristian and Jurafsky, Dan and Leskovec, Jure},
  year = {2018},
  pages = {20},
  abstract = {A community's identity defines and shapes its internal dynamics. Our current understanding of this interplay is mostly limited to glimpses gathered from isolated studies of individual communities. In this work we provide a systematic exploration of the nature of this relation across a wide variety of online communities. To this end we introduce a quantitative, language-based typology reflecting two key aspects of a community's identity: how distinctive, and how temporally dynamic it is. By mapping almost 300 Reddit communities into the landscape induced by this typology, we reveal regularities in how patterns of user engagement vary with the characteristics of a community.},
  langid = {english},
  keywords = {cclm-rw}
}
% == BibTeX quality report for Zhang2018:
% Missing required field 'journal'
% ? Title looks like it was stored in title-case in Zotero
% ? Unused libraryCatalog: Zotero
% ? Unused version: 741


% Required packages:
% * textcomp


@article{Brown2020,
  title = {Language {{Models}} Are {{Few}}-{{Shot Learners}}},
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and {Herbert-Voss}, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  year = {2020},
  month = jul,
  journal = {arXiv:2005.14165 [cs]},
  eprint = {2005.14165},
  eprinttype = {arxiv},
  primaryclass = {cs},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language}
}

@inproceedings{Devlin2019,
  ids = {Devlin2019a},
  title = {{{BERT}}: Pre-Training of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  booktitle = {Proceedings of the 2019 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: Human {{Language Technologies}}, {{Volume}} 1 ({{Long}} and {{Short Papers}})},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year = {2019},
  month = jun,
  pages = {4171--4186},
  publisher = {{Association for Computational Linguistics}},
  address = {{Minneapolis, Minnesota}},
  doi = {10.18653/v1/N19-1423},
}

@inproceedings{Lui2012,
  title = {Langid.Py: An {{Off}}-the-Shelf {{Language Identification Tool}}},
  shorttitle = {Langid.Py},
  booktitle = {Proceedings of the {{ACL}} 2012 {{System Demonstrations}}},
  author = {Lui, Marco and Baldwin, Timothy},
  year = {2012},
  month = jul,
  pages = {25--30},
  publisher = {{Association for Computational Linguistics}},
  address = {{Jeju Island, Korea}}
}


