
@article{Bamman2014,
  title = {Gender Identity and Lexical Variation in Social Media},
  author = {Bamman, David and Eisenstein, Jacob and Schnoebelen, Tyler},
  year = {2014},
  volume = {18},
  pages = {135--160},
  issn = {1467-9841},
  doi = {10.1111/josl.12080},
  abstract = {We present a study of the relationship between gender, linguistic style, and social networks, using a novel corpus of 14,000 Twitter users. Prior quantitative work on gender often treats this social variable as a female/male binary; we argue for a more nuanced approach. By clustering Twitter users, we find a natural decomposition of the dataset into various styles and topical interests. Many clusters have strong gender orientations, but their use of linguistic resources sometimes directly conflicts with the population-level language statistics. We view these clusters as a more accurate reflection of the multifaceted nature of gendered language styles. Previous corpus-based work has also had little to say about individuals whose linguistic styles defy population-level gender patterns. To identify such individuals, we train a statistical classifier, and measure the classifier confidence for each individual in the dataset. Examining individuals whose language does not match the classifier's model for their gender, we find that they have social networks that include significantly fewer same-gender social connections and that, in general, social network homophily is correlated with the use of same-gender language markers. Pairing computational methods and social theory thus offers a new perspective on how gender emerges as individuals position themselves relative to audiences, topics, and mainstream gender norms.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/josl.12080},
  copyright = {\textcopyright{} 2014 John Wiley \& Sons Ltd},
  file = {/Users/xnobwi/.zotero/storage/CJSGAFPE/Bamman et al. - 2014 - Gender identity and lexical variation in social me.pdf},
  journal = {Journal of Sociolinguistics},
  keywords = {computational methods,computer-mediated communication,Gender,social media,social networks,style},
  language = {en},
  number = {2}
}

@inproceedings{Bamman2014a,
  title = {Distributed {{Representations}} of {{Geographically Situated Language}}},
  booktitle = {Proceedings of the 52nd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 2: {{Short Papers}})},
  author = {Bamman, David and Dyer, Chris and Smith, Noah A.},
  year = {2014},
  month = jun,
  pages = {828--834},
  publisher = {{Association for Computational Linguistics}},
  address = {{Baltimore, Maryland}},
  doi = {10.3115/v1/P14-2134},
  file = {/Users/xnobwi/.zotero/storage/5XXXZMPB/Bamman et al. - 2014 - Distributed Representations of Geographically Situ.pdf}
}

@article{Baumgartner2020,
  title = {The {{Pushshift Reddit Dataset}}},
  author = {Baumgartner, Jason and Zannettou, Savvas and Keegan, Brian and Squire, Megan and Blackburn, Jeremy},
  year = {2020},
  month = jan,
  abstract = {Social media data has become crucial to the advancement of scientific understanding. However, even though it has become ubiquitous, just collecting large-scale social media data involves a high degree of engineering skill set and computational resources. In fact, research is often times gated by data engineering problems that must be overcome before analysis can proceed. This has resulted recognition of datasets as meaningful research contributions in and of themselves.},
  archivePrefix = {arXiv},
  eprint = {2001.08435},
  eprinttype = {arxiv},
  file = {/Users/xnobwi/.zotero/storage/EKD4IX6E/Baumgartner et al. - 2020 - The Pushshift Reddit Dataset.pdf},
  journal = {arXiv:2001.08435 [cs]},
  keywords = {Computer Science - Computers and Society,Computer Science - Social and Information Networks},
  language = {en},
  primaryClass = {cs}
}

@inproceedings{DelTredici2017,
  title = {Semantic {{Variation}} in {{Online Communities}} of {{Practice}}},
  booktitle = {{{IWCS}} 2017 - 12th {{International Conference}} on {{Computational Semantics}} - {{Long}} Papers},
  author = {Del Tredici, Marco and Fern{\'a}ndez, Raquel},
  year = {2017},
  file = {/Users/xnobwi/.zotero/storage/ZM6ANXTV/Tredici and Fern√°ndez - 2017 - Semantic Variation in Online Communities of Practi.pdf}
}

@misc{Honnibal2017,
  title = {{{spaCy}} 2: {{Natural}} Language Understanding with {{Bloom}} Embeddings, Convolutional Neural Networks and Incremental Parsing},
  author = {Honnibal, Matthew and Montani, Ines},
  year = {2017},
  howpublished = {Explosion}
}

@inproceedings{Kumar2018,
  title = {Community {{Interaction}} and {{Conflict}} on the {{Web}}},
  booktitle = {Proceedings of the 2018 {{World Wide Web Conference}} on {{World Wide Web}} - {{WWW}} '18},
  author = {Kumar, Srijan and Hamilton, William L. and Leskovec, Jure and Jurafsky, Dan},
  year = {2018},
  pages = {933--943},
  publisher = {{ACM Press}},
  address = {{Lyon, France}},
  doi = {10.1145/3178876.3186141},
  abstract = {Users organize themselves into communities on web platform60 s. These communities can interact with one another, often leading to conflicts and toxic interactions. However, little is known about the mechanisms of interactions between communities and how th40ey impact users.},
  file = {/Users/xnobwi/.zotero/storage/IUCJX983/Kumar et al. - 2018 - Community Interaction and Conflict on the Web.pdf},
  isbn = {978-1-4503-5639-8},
  language = {en}
}

@article{Lau2017,
  title = {Grammaticality, {{Acceptability}}, and {{Probability}}: {{A Probabilistic View}} of {{Linguistic Knowledge}}},
  shorttitle = {Grammaticality, {{Acceptability}}, and {{Probability}}},
  author = {Lau, Jey Han and Clark, Alexander and Lappin, Shalom},
  year = {2017},
  volume = {41},
  pages = {1202--1241},
  issn = {1551-6709},
  doi = {10.1111/cogs.12414},
  abstract = {The question of whether humans represent grammatical knowledge as a binary condition on membership in a set of well-formed sentences, or as a probabilistic property has been the subject of debate among linguists, psychologists, and cognitive scientists for many decades. Acceptability judgments present a serious problem for both classical binary and probabilistic theories of grammaticality. These judgements are gradient in nature, and so cannot be directly accommodated in a binary formal grammar. However, it is also not possible to simply reduce acceptability to probability. The acceptability of a sentence is not the same as the likelihood of its occurrence, which is, in part, determined by factors like sentence length and lexical frequency. In this paper, we present the results of a set of large-scale experiments using crowd-sourced acceptability judgments that demonstrate gradience to be a pervasive feature in acceptability judgments. We then show how one can predict acceptability judgments on the basis of probability by augmenting probabilistic language models with an acceptability measure. This is a function that normalizes probability values to eliminate the confounding factors of length and lexical frequency. We describe a sequence of modeling experiments with unsupervised language models drawn from state-of-the-art machine learning methods in natural language processing. Several of these models achieve very encouraging levels of accuracy in the acceptability prediction task, as measured by the correlation between the acceptability measure scores and mean human acceptability values. We consider the relevance of these results to the debate on the nature of grammatical competence, and we argue that they support the view that linguistic knowledge can be intrinsically probabilistic.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12414},
  copyright = {Copyright \textcopyright{} 2016 Cognitive Science Society, Inc.},
  file = {/Users/xnobwi/.zotero/storage/8Q4WVS6A/Lau et al. - 2017 - Grammaticality, Acceptability, and Probability A .pdf},
  journal = {Cognitive Science},
  keywords = {Grammaticality,Probabilistic modeling,Syntactic knowledge},
  language = {en},
  number = {5}
}

@inproceedings{Lau2017a,
  title = {Topically {{Driven Neural Language Model}}},
  booktitle = {Proceedings of the 55th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Lau, Jey Han and Baldwin, Timothy and Cohn, Trevor},
  year = {2017},
  month = jul,
  pages = {355--365},
  publisher = {{Association for Computational Linguistics}},
  address = {{Vancouver, Canada}},
  doi = {10.18653/v1/P17-1033},
  abstract = {Language models are typically applied at the sentence level, without access to the broader document context. We present a neural language model that incorporates document context in the form of a topic model-like architecture, thus providing a succinct representation of the broader document context outside of the current sentence. Experiments over a range of datasets demonstrate that our model outperforms a pure sentence-based model in terms of language model perplexity, and leads to topics that are potentially more coherent than those produced by a standard LDA topic model. Our model also has the ability to generate related sentences for a topic, providing another way to interpret topics.},
  file = {/Users/xnobwi/.zotero/storage/UAR39YDR/Lau et al. - 2017 - Topically Driven Neural Language Model.pdf}
}

@article{Loshchilov2019,
  title = {Decoupled {{Weight Decay Regularization}}},
  author = {Loshchilov, Ilya and Hutter, Frank},
  year = {2019},
  month = jan,
  abstract = {L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is \textbackslash emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it "weight decay" in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by \textbackslash emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at https://github.com/loshchil/AdamW-and-SGDW},
  archivePrefix = {arXiv},
  eprint = {1711.05101},
  eprinttype = {arxiv},
  file = {/Users/xnobwi/.zotero/storage/M5NJK34K/Loshchilov and Hutter - 2019 - Decoupled Weight Decay Regularization.pdf},
  journal = {arXiv:1711.05101 [cs, math]},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Mathematics - Optimization and Control},
  primaryClass = {cs, math}
}

@inproceedings{Martin2017,
  title = {Community2vec: {{Vector}} Representations of Online Communities Encode Semantic Relationships},
  shorttitle = {Community2vec},
  booktitle = {Proceedings of the {{Second Workshop}} on {{NLP}} and {{Computational Social Science}}},
  author = {Martin, Trevor},
  year = {2017},
  month = aug,
  pages = {27--31},
  publisher = {{Association for Computational Linguistics}},
  address = {{Vancouver, Canada}},
  doi = {10.18653/v1/W17-2904},
  abstract = {Vector embeddings of words have been shown to encode meaningful semantic relationships that enable solving of complex analogies. This vector embedding concept has been extended successfully to many different domains and in this paper we both create and visualize vector representations of an unstructured collection of online communities based on user participation. Further, we quantitatively and qualitatively show that these representations allow solving of semantically meaningful community analogies and also other more general types of relationships. These results could help improve community recommendation engines and also serve as a tool for sociological studies of community relatedness.},
  file = {/Users/xnobwi/.zotero/storage/LITBFRMX/Martin - 2017 - community2vec Vector representations of online co.pdf}
}


