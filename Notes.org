

* On what level of linguistic analysis is variation is happening between communities?

Experiments:
 - train transformer model with added community embedding at various levels.
 - test if the model can predict which community a message is coming from
   - leading idea:
     - to get the community embedding, multiply matrix of community
       embeddings by a weight W.
       - in training W is a one-hot encoding of the community.
         - Or, if data is the whole training set, W is the identity matrix
       - in testing, let W be optimised (and the rest is fixed)
         - actually it's convenient to optimise the community
           embeddings all at once, and let W be a c*c matrix. The ith
           row is selected when facing a message from community i.
         - Then entropy of W (seen as a distribution) gives a level of
           confidence about the community.
         - data is: a single input. (and all the things that were
           parameter before are fixed and thus treated as input data)
     - so W(i) tells you the distribution of communities from the set
       of messages assigned we assigned to i.
     - entropy of W(i) is low if the community i is very specific from
       the point of view of our (linguistic) model (so messages can be
       easily identified as comming from a specific community; ie they
       get assigned a significantly higher loss if considered from the
       wrong community.).
     - actually W can be seen as a confusion matrix. So we can 'boil
       it' down to a combined F score measuring the ability to
       identify a community.
     - TODO: scatterplot for 2 models.

* Analysis of model quality

- P_m(i) = average loss per message, for community i, for model m.
- Analysis of difference in information gains for simple/complex models:
- Plot P_m(i) vs P_n(i) for each i (gives scatterplot, which shows
  information gain between m and n for each community.)
  - eg. bigram model loss vs. transformer model loss.


* Analysis of community embeddings


- Correlation with the extra-linguistic properties of communities?.
  - for example using a single dense layer + softmax
  - Frequency of image posts?
  - Mean number of post per user. (or the correponding power law
    exponent estimator:
    https://en.wikipedia.org/wiki/Power_law#Maximum_likelihood)
  - Proportion of comments which are replies to other comments
  - Community/People co-occurence matrix / LSA
    - construct the matrix as follows:
      - for each message posted by user u in community c, M (u,c) += 1
      - apply LSA

- Correlation between embeddings of several models.
  - Basic idea: check the Pearson correlation beween cosine similarity (c^m_i, c^m_j) for every
    pair of community (j,i), between to models (m).
  - If r=1, then you have a perfect orthogonal mapping
  - This is a very strong condition, because all dimensions play some role.
    Other idea is to do a projection on the n most relevant dimensions first.
     - For n=1 this is checking that the most relevant dimension is the same for both models
     - To do this, do a LSA/SVD decomp of embeddings first
       (sklearn.decomposition.TruncatedSVD), and truncate at n dimensions.
       sklearn.decomposition.TruncatedSVD(n_components=n)
     - Then compute Pearson correlation

* Open questions:
-  Where in the architecture should the embedding go in general
- Can the topically-driven language model smooth the embedding

* Related work:

** Topic modelling
- Discovering Discrete Latent Topics with Neural Variational Inference https://arxiv.org/pdf/1706.00359.pdf
- JeyHan Lau's work
